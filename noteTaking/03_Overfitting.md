# Overfitting

- 샘플 데이터에 잘 맞는 모델을 만들었다해도 실제로 사용할 때는 정확도가 떨어짐

## 과적합의 원인

- 학습 샘플 데이터 수의 부족
    - 데이터의 수가 많을수록 모집단의 특성을 잘 반영할 확률이 높음
    - 우리가 갖는 데이터의 모집단의 특성을 잘 반영할수록 과적합 확률이 적어짐
- 풀고자 하는 문제에 비해 복잡한 모델 적용
    - 간단한 문제에 대해서는 간단한 모델 또는 적은 변수만 사용하는 것이 과적합을 줄임
    - 모델이 복잡하다는 것은 많은 변수를 사용하거나 모델 자체가 복잡한 모델(딥러닝 등)을 의미

## 과적합의 방지 : 적합성 평가

- 가장 이상적인 방법은 데이터의 수를 늘리고, 풀고자 하는 문제에 적합한 모델을 사용
- 그러나 모델을 잘 선택한다 하더라도 현재 모델이 과적합 되었는지 확인하는 과정이 필요
- 현재 갖는 데이터를 분할하여 모델의 과적합 정도를 판단해야 함
    - 학습 데이터와 검증 데이터로 분할
    - 학습 데이터로 모델 학습을 진행
    - 검증 데이터로 모델에 적용시켜 과적합 여부를 판단

- 학습 데이터 (train) : 학습을 위한 데이터
    - ML 모델 함수 f를 적합시킬 데이터
- 검증 데이터 (validate) : 함수 f를 검증시킬 데이터
    - 검증 데이터의 성능 지표를 보며 최적의 파라미터를 선정
- 테스트 데이터 (test) : 모델의 성능을 최종적으로 측정하는 데이터
- 보통 train:validate:test=4:3:3 이나 train:test=8:2 로 분할함

- ![](https://t1.daumcdn.net/cfile/tistory/9951E5445AAE1BE025)

## K-Fold Cross Validation

- 데이터가 부족해 분할하기 어려운 경우에 사용하는 기법

1. 데이터를 랜덤하게 k개의 fold로 구분함 (k는 하이퍼파라미터, 보통 5 또는 10으로 설정)
1. 첫 번째 fold를 제외한 나머지 fold 데이터를 합쳐 학습 데이터로 사용하고 첫 번째 fold를 검증 데이터로 사용
1. 그 다음 두 번째 fold를 검증데이터로 사용하고 두 번째를 제외한 나머지 fold 데이터를 학습 데이터로 사용
1. 위 과정을 k번 반복하여 모든 데이터를 학습 데이터와 검증 데이터로 사용할 수 있음

- ![](https://upload.wikimedia.org/wikipedia/commons/b/b5/K-fold_cross_validation_EN.svg)